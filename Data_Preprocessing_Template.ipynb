{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51fafad",
   "metadata": {},
   "source": [
    "# Data Preprocessing Template\n",
    "\n",
    "Covering the more significant steps:\n",
    "\n",
    "* Import libraries\n",
    "* Import data\n",
    " * Import data from csv, json, excel and html\n",
    " * Import data from SQL query\n",
    " * Create a Data Frame from list of lists, list of dictionaries and array\n",
    "* Data visualization\n",
    " * Basic information\n",
    " * Data selection\n",
    "* Clean Data\n",
    " * Outliers\n",
    " * Duplicates\n",
    " * Strip spaces\n",
    "* Taking care of missing data\n",
    " * Count Nan / Null values\n",
    " * Delete\n",
    " * Replace\n",
    "* Encoding the categorical data \n",
    " * Replace manually\n",
    " * Label Encoding\n",
    " * One Hot Encoder\n",
    "* Splitting the dataset\n",
    "* Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa951d48",
   "metadata": {},
   "source": [
    "For further information, please read the reference guidelines for the pandas API: https://pandas.pydata.org/docs/reference/index.html#api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6728750",
   "metadata": {},
   "source": [
    "## -- Import libraries --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff06a28",
   "metadata": {},
   "source": [
    "### Import the most important libraries at the beginning\n",
    "As a first step, we need to import the common libraries, for further steps, other libraries would be added in the correspondent cell or added in this section, source of libraries to use:\n",
    "https://www.dataquest.io/blog/15-python-libraries-for-data-science/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940028bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrays\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc04b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e7ae0",
   "metadata": {},
   "source": [
    "## -- Import data --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea8137",
   "metadata": {},
   "source": [
    "### Import data from csv, json, excel and html\n",
    "How to import data from different formats, sources and full examples:\n",
    "import json and html: https://www.datacamp.com/community/tutorials/importing-data-into-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359aac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from csv file\n",
    "df = pd.read_csv('Datapath.csv') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from json file\n",
    "df = pd.read_json('Datapath.json') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from excel file\n",
    "df = pd.read_excel('Datapath.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from excel sheet\n",
    "df = pd.read_excel('Datapath.xlsx', sheet_name='your Excel sheet name')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from html\n",
    "import requests \n",
    "url = 'https://www.path.com/' \n",
    "path_url = requests.get(url) \n",
    "df = pd.read_html(path_url.text)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c685f6",
   "metadata": {},
   "source": [
    "### Import data from SQL query\n",
    "How to import data using SQL queries, for the full example:\n",
    "https://datatofish.com/sql-to-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc0d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from SQL\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('test_database') \n",
    "sql_query = pd.read_sql_query ('''SELECT * FROM products ''', conn)\n",
    "df = pd.DataFrame(sql_query, columns = ['column1', 'column2', 'column3'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df3f37",
   "metadata": {},
   "source": [
    "### Create a Data Frame from list of lists, list of dictionaries and array\n",
    "Create a Data Frame from other pandas or numpy objects, source:\n",
    "https://www.w3resource.com/pandas/dataframe/dataframe.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcf6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from list of lists pd.DataFrame(data, index, columns, dtype)\n",
    "df = pd.DataFrame([['María', 18], ['Luis', 22], ['Carmen', 20]], columns=['Nombre', 'Edad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from list of dictionaries 1 pd.DataFrame(data, index, columns, dtype)\n",
    "df = pd.DataFrame([{'Nombre':'María', 'Edad':18}, {'Nombre':'Luis', 'Edad':22}, {'Nombre':'Carmen'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from list of dictionaries 2 pd.DataFrame(data, index, columns, dtype)\n",
    "df = pd.DataFrame({'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from array pd.DataFrame(data, index, columns, dtype)\n",
    "df = pd.DataFrame(np.random.randn(4, 3), columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3079ce8",
   "metadata": {},
   "source": [
    "## -- Data visualization --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45282630",
   "metadata": {},
   "source": [
    "### Basic information\n",
    "In this section we can visualize basic information from the data frame imported to have a clear vision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f568052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print percentile, mean, std\n",
    "Print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print basic information \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14909f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print number of columns and rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39fe9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print names of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print names of rows\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print n first rows (by default 5 df.head())\n",
    "df.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print n last rows (by default 5 df.tail())\n",
    "df.tail(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of elements of every value\n",
    "df[\"column name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf8012",
   "metadata": {},
   "source": [
    "### Data selection\n",
    "Select parts of the Data Frame, sources and entire examples:\n",
    "loc: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "iloc: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elements by number of rows and columns\n",
    "print(df.iloc[num_row,num_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elements in rows and columns (':' means from the beginning to (by default to the end))\n",
    "print(df.loc[2, 'column1']) #example 1\n",
    "print(df.loc[:3, ('column1','column2')]) #example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elements of row number\n",
    "print(df.iloc[num_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb81f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elements of column name\n",
    "print(df['column name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c5bae",
   "metadata": {},
   "source": [
    "#### Assign elements to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a97ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all rows, all columns except the last one\n",
    "X = dataset.iloc[:, :-1].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdeb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all rows, last column\n",
    "y = dataset.iloc[:, -1].values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ef407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns by data type\n",
    "obj_df = df.select_dtypes(include=['object']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c74b46",
   "metadata": {},
   "source": [
    "## -- Clean Data --\n",
    "In this section we will take care of anomalies in the data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb3c20",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "source and full examples:\n",
    "https://www.analyticsvidhya.com/blog/2021/06/how-to-clean-data-in-python-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea71f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first it is recommended to plot the column to visualize the outliers\n",
    "df.colummn.plot(kind='box', figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers\n",
    "df = df.loc[df.column < 9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e011f94",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "source: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b522f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicated values\n",
    "df.drop_duplicates(subset=name, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf8068",
   "metadata": {},
   "source": [
    "### Strip spaces\n",
    "source: https://www.datasciencemadesimple.com/strip-space-column-pandas-dataframe-leading-trailing-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip leading and trailing spaces\n",
    "df['column'] = df['column'].str.strip()\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a806133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip only leading space\n",
    "df['column'] = df['column'].str.lstrip()\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b087c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip only trailing space\n",
    "df['column'] = df['column'].str.rstrip()\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436237ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip all spaces\n",
    "df['column'] = df['solumn'].str.replace(\" \",\"\")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0439319",
   "metadata": {},
   "source": [
    "## -- Taking care of missing values --\n",
    "In this section we will cover how to deal with missing values, as we can't compute ML models with this kind of values\n",
    "Source: https://www.analyticsvidhya.com/blog/2021/05/dealing-with-missing-values-in-python-a-complete-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6edbfa",
   "metadata": {},
   "source": [
    "### Count Nan / Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ee743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count Nan values\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count Null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see null values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b045de",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns\n",
    "df = df.drop(['column1','column2'], axis=1, inplace=True) #axis=1 for columns, axis=0 for rows (by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows\n",
    "df = df.drop([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21700c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows with Nan values\n",
    "df = df.dropna() #by default axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea037aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns with Nan values\n",
    "df = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabbd936",
   "metadata": {},
   "source": [
    "### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc557994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace Nan values by a number n\n",
    "df.fillna(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nan value by a category\n",
    "obj_df = obj_df.fillna({\"num_doors\": \"four\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ecd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace Nan values by mean of the column option 1\n",
    "df['column']=df['column'].fillna(df['column'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace Nan values by mean of the column option 2\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace Nan values by median\n",
    "dataset[\"column\"] = dataset[\"column\"].replace(np.NaN, dataset[\"column\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace Nan values by mode\n",
    "import statistics\n",
    "dataset[\"column\"] = dataset[\"column\"].replace(np.NaN, statistics.mode(dataset[\"column\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace by Linear Interpolation\n",
    "dataset[\"column\"] = dataset[\"column\"].interpolate(method='linear', limit_direction='forward', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace by last observation carried forward LOCF\n",
    "dataset[\"column\"] = dataset[\"column\"].fillna(method ='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a42c1a",
   "metadata": {},
   "source": [
    "#### Replace using Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values with regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "df.head()\n",
    "testdf = df[df['column'].isnull()==True]\n",
    "traindf = df[df['column'].isnull()==False]\n",
    "y = traindf['column']\n",
    "traindf.drop('column',axis=1,inplace=True)\n",
    "lr.fit(traindf,y)\n",
    "testdf.drop('column',axis=1,inplace=True)\n",
    "pred = lr.predict(testdf)\n",
    "testdf['column']= pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02c74d",
   "metadata": {},
   "source": [
    "## -- Encoding the categorical data --\n",
    "In this section we transform the categorical data in numbers in order to operate with ML models, source:\n",
    "https://pbpython.com/categorical-encoding.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226ef12",
   "metadata": {},
   "source": [
    "### Replace manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using replace and a dictionary\n",
    "cleanup_nums = {\"column1\": {\"value1\": 4, \"value2\": 2},\n",
    "                \"column2\": {\"value1\": 4, \"value2\": 6, \"value3\": 5, \"value4\": 8}}\n",
    "df = df.replace(cleanup_nums) #we replace using the replace function and adding the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af1c49",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encoding\n",
    "obj_df[\"column1\"] = obj_df[\"column1\"].astype('category') #change the type to category\n",
    "obj_df[\"column1_cat\"] = obj_df[\"column1\"].cat.codes #apply cat codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0424cc",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad107ed",
   "metadata": {},
   "source": [
    "#### Encoding the independent variable\n",
    "before use this command, be sure to assign a portion of the data frame to X (portion with independent variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c0e9b",
   "metadata": {},
   "source": [
    "#### Encoding the dependent variable\n",
    "before use this command, be sure to assign a portion of the data frame to y (portion with the dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e21b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af06aa",
   "metadata": {},
   "source": [
    "## -- Splitting the dataset --\n",
    "Before fit the data to the ML supervised models, we need to split the data set in training set and test set, normally 20% for the test set and 80% for the training set (you can adjust the quantity), source and full examples: https://realpython.com/train-test-split-python-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07745f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set in training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1) #20% of the data to the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a65e63",
   "metadata": {},
   "source": [
    "## -- Feature Scaling --\n",
    "Finally and before apply ML models, sometimes (especially when we have data with highly varying magnitudes or values or units) we need to standardize the independent features present in the data in a fixed range, source and complete examples:\n",
    "https://www.analyticsvidhya.com/blog/2021/05/feature-scaling-techniques-in-python-a-complete-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
